import torch
import torch.nn as nn
import torch.optim as optim
import random
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from sklearn.model_selection import train_test_split
import numpy as np

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
def generate_data(n_samples=1000, x_min=0, x_max=50, limit=100, step_min=1, step_max=10):
    data = []
    for _ in range(n_samples):
        x0 = random.uniform(x_min, x_max)
        step = random.uniform(step_min, step_max)
        steps_needed = int((limit - x0) / step)
        data.append([x0, step, steps_needed])
    return data, limit

# –î–∞–Ω–Ω—ã–µ
data, limit = generate_data(2000)
data = np.array(data)
X = data[:, :2]  # x0, step
y = data[:, 2]   # steps_needed

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
X_mean, X_std = X.mean(axis=0), X.std(axis=0)
X = (X - X_mean) / X_std
y = y.reshape(-1, 1)

# –¢—Ä–µ–Ω/—Ç–µ—Å—Ç
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.float32)

# –ú–æ–¥–µ–ª—å
class StepPredictor(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(2, 16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 1)
        )
    def forward(self, x):
        return self.model(x)

model = StepPredictor()
loss_fn = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# –û–±—É—á–µ–Ω–∏–µ
for epoch in range(200):
    model.train()
    pred = model(X_train)
    loss = loss_fn(pred, y_train)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        print(f"Epoch {epoch}: Loss = {loss.item():.4f}")

# –ü—Ä–∏–º–µ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
example_x0 = 25.0
example_step = 4.2

# –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è –º–æ–¥–µ–ª–∏
example_input = torch.tensor([[
    (example_x0 - X_mean[0]) / X_std[0],
    (example_step - X_mean[1]) / X_std[1]
]], dtype=torch.float32)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
model.eval()
with torch.no_grad():
    predicted_steps = model(example_input).item()

true_steps = int((limit - example_x0) / example_step)

print(f"\nüìä –†–µ–∞–ª—å–Ω—ã–µ —à–∞–≥–∏ –¥–æ –ø—Ä–µ–¥–µ–ª–∞: {true_steps}")
print(f"ü§ñ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª—å—é —à–∞–≥–∏: {predicted_steps:.1f}")

# --------- –ê–ù–ò–ú–ê–¶–ò–Ø ---------
x_values = [example_x0]
while x_values[-1] < limit:
    x_values.append(x_values[-1] + example_step)
time_steps = list(range(len(x_values)))

fig, ax = plt.subplots()
line, = ax.plot([], [], 'bo-', label='–ó–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞')
limit_line = ax.axhline(y=limit, color='r', linestyle='--', label='–ü—Ä–µ–¥–µ–ª')

ax.set_xlim(0, len(x_values))
ax.set_ylim(example_x0 - 5, limit + 10)
ax.set_title("–ê–Ω–∏–º–∞—Ü–∏—è –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏—è –∫ –ø—Ä–µ–¥–µ–ª—å–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é")
ax.set_xlabel("–®–∞–≥")
ax.set_ylabel("–ó–Ω–∞—á–µ–Ω–∏–µ")
ax.legend()

def update(frame):
    line.set_data(time_steps[:frame+1], x_values[:frame+1])
    return line,

ani = animation.FuncAnimation(fig, update, frames=len(x_values), interval=400, repeat=False)

plt.show()